<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>YOLOv8详解</title>
    <link href="/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/"/>
    <url>/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062225432.png" alt="image.png"></p><p>​                                                                                     The YOLO Timeline</p><h3 id="1-YOLOV8-概述"><a href="#1-YOLOV8-概述" class="headerlink" title="1. YOLOV8 概述"></a>1. YOLOV8 概述</h3><p>整体网络在YOLOV5的基础上进行了优化，并结合了YOLOV7的ELAN算法思想，基于缩放系数提供了n&#x2F;s&#x2F;m&#x2F;l&#x2F;x五种参数量依次增大的模型，并通过一套框架实现实例分割、姿势&#x2F;关键点检测、目标检测和分类支持多种复杂任务<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://github.com/ultralytics/ultralytics">[1]</span></a></sup>。 <img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062231676.png"></p><p>​                                                   图1 一套框架实现不同任务(源自<a href="https://github.com/ultralytics/ultralytics">https://github.com/ultralytics/ultralytics</a>)</p><h3 id="2-YOLOv8检测算法整体模型结构"><a href="#2-YOLOv8检测算法整体模型结构" class="headerlink" title="2. YOLOv8检测算法整体模型结构"></a>2. YOLOv8检测算法整体模型结构</h3><p><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405151132320.png" alt="image.png"><br>                                                   图2 整体结构图(源自<a href="https://github.com/open-mmlab/mmyolo/tree/dev/configs/yolov8">https://github.com/open-mmlab/mmyolo/tree/dev/configs/yolov8</a>)</p><p>从两个模型的yaml文件可以看出，不同尺度大小的模型，yolov5的最大通道采用了统一大小的最大通道，均为1024，yolov8中n&#x2F;s、l&#x2F;x分别采用了相同大小的最大通达，s&#x2F;m&#x2F;l则进行了精调, 主要目的是为了平衡各个模型的参数量。<br><img src="D:/document/Obsidian/deep%2520learning/paper%2520%2520read/YOLOs/images/Pasted%2520image%252020240122161239.png"></p><p>​                                                                            图3 YOLOv8与YOLOv5模型系数比较</p><h3 id="2-1-Backbone"><a href="#2-1-Backbone" class="headerlink" title="2.1 Backbone"></a>2.1 Backbone</h3><p><img src="D:/document/Obsidian/deep%2520learning/paper%2520%2520read/YOLOs/images/Pasted%2520image%252020240122162925.png"></p><p>​                                                                               图4 YOLOv8与YOLOv5的Backbone比较</p><p><strong>Backbone中yolov5和yolov8主要有两点差异:</strong><br>(1) 提取初步特征的第一个卷积层的卷积核kernel，yolov5为6x6, yolov8为3x3，感受野相比于yolov5进一步缩小<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://juejin.cn/post/7187726947252699192">[2]</span></a></sup>。</p><p>(2) yolov5中的C3模块在yolov8中被替换为了C2f，C2f则采用了yolov7中ELAN 多层堆叠的结构，增加了更多类似resnet残差块中的跳跃连接,丰富了模型的梯度流。<br><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405132056678.png" alt="image.png"><br>                                                                     图5 C3与C2f对比图(源自<a href="https://openmmlab.medium.com/dive-into-yolov8-how-does-this-state-of-the-art-model-work-10f18f74bab1">https://openmmlab.medium.com/dive-into-yolov8-how-does-this-state-of-the-art-model-work-10f18f74bab1</a>)</p><h4 id="2-1-1-SPPF模块"><a href="#2-1-1-SPPF模块" class="headerlink" title="2.1.1 SPPF模块"></a>2.1.1 SPPF模块</h4><p><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062235111.png" alt="image.png"></p><p>​                                                         图6 SPP与SPPF比较</p><p>SPP与SPPF有着相同的作用:实现多尺度特征融合。原始的SPP模块是由Joseph Redmon 在 YOLOv3 中实现的，采用不同大小池化kernel的并行结构，而SPPF首次使用是在YOLOv5中，采用了三个相同大小池化Kernel的并行+串行的结构, 增加了更多的跳跃连接。<br>为什么左侧SPP的Maxpooling，其kernel size分别是5，9，13, 而右侧SPPF的kernel size均是5呢？我们用感受野的公式计算一下感受野:<br>$$\begin{aligned}r_l&amp;&#x3D;r_{l-1}+\left((k_l-1)*\prod_{i&#x3D;1}^{l-1}s_i\right), l&gt;&#x3D;2\end{aligned}\tag{1}$$<br>其中: $r_{l}$为第$l$层的感受野， $k_l$为第$l$层的kernel size，$s_i$为步长stride。<br>假设conv2d+BN+SiLU为第一层，令$r_{1}$为1，则有:</p><table><thead><tr><th align="center">右侧</th><th align="center">左侧</th></tr></thead><tbody><tr><td align="center">$r_{k_1&#x3D;5}$&#x3D; 1+4*1&#x3D;5</td><td align="center">$r_{k&#x3D;5}$ &#x3D; 1+4*1&#x3D;5</td></tr><tr><td align="center">$r_{k_2&#x3D;5}$&#x3D; 5+4*1&#x3D;9</td><td align="center">$r_{k&#x3D;9}$ &#x3D; 1+8*1&#x3D;9</td></tr><tr><td align="center">$r_{k_3&#x3D;5}$&#x3D; 9+4*1&#x3D;13</td><td align="center">$r_{k&#x3D;13}$ &#x3D; 1+12*1&#x3D;13</td></tr></tbody></table><p>可以发现SPP和SPPF有着相同的感受野，但SPPF的浮点运算量更少，所以速度更快<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://github.com/ultralytics/yolov5/issues/8785">[3]</span></a></sup>。</p><h3 id="2-2-Neck"><a href="#2-2-Neck" class="headerlink" title="2.2 Neck"></a>2.2 Neck</h3><p>Neck部分采用FPN和PAN结合的结构，实现浅层特征与深层特征的相互融合，共提取三个有效特征层给Head: feat1&#x3D;(80, 80, 256*$w$)、feat2&#x3D;(40, 40, 512*$w$)、feat3&#x3D;(20, 20, 512$<em>w</em>r$){其中$w,r$为模型系数}, 并将三个特征层作为Head的输入。</p><h3 id="2-3-Head"><a href="#2-3-Head" class="headerlink" title="2.3 Head"></a>2.3 Head</h3><table><thead><tr><th><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405131645079.png"></th></tr></thead><tbody><tr><td></td></tr><tr><td><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405141639782.png" alt="image.png"><br><br></td></tr></tbody></table><p>yolov5、yolox和yolov8三者的Head中，yolov5为ancher base，yolov8和yolox为ancher free, 并且yolov8和yolox均用了decoupled detection head(两个并行分支分别完成检测和分类，yolox的论文显示采用decoupled detection head能够提升AP约1.1个百分点<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://arxiv.org/abs/2107.08430">[4]</span></a></sup>),预测输出方面:</p><p>yolov5: 对于特征图上的每一个grid cell预测($N_{cls}$ + 4 + 1)x3个参数，其中$N_{cls}$表示类别数，<code>4</code>表示网络预测bbox的相关参数，<code>1</code>表示是否有目标。</p><p>yolox: 对于特征图上的每个grid point预测($N_{cls}$ + 4 + 1)个参数。$N_{cls}$、<code>4</code>、<code>1</code>的含义和yolov5相同。对于有80个类别的coco数据集， 三个检查头所预测的参数个数分别为80x80x(80 + 4 + 1)、40x40x(80 + 4 + 1)、20x20x(80 + 4 + 1)个参数。</p><p>yolov8: yolov8消除了yolox中判断是否有物体的obj. 分支， 对于特征图上的每个特征点预测($N_{cls}$ + 4* $\text{reg_max}$)个参数，在yolox中分类和回归分支的通道数均为256，yolov8认为作为两个不同的分支，用于表征不同的特征，通道数不应该是相等的<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://zhuanlan.zhihu.com/p/599761847">[5]</span></a></sup>，对于分类分支通倒数$C_{cls}$ 设置为$max(C^{3},min(N_{cls},100))$，回归分支的通道数$C_{reg}$为$max(16,C^{3}&#x2F;4,4<em>\text{reg_max})$。对于有80个类别的coco数据集，假设$\text{reg_max}$为16，$w$取1:<br>$$\begin{aligned}<br>&amp;C_{cls}&#x3D;max(256,min(80, 100))&#x3D;256 \<br>&amp;C_{reg}&#x3D;max(16,256&#x2F;4,4</em>16)&#x3D;64<br>\end{aligned}$$<br>对于YOLOv8两个分支最后的Conv2d模块:</p><pre><code class="hljs"> 1. 类别预测分支输出的维度为:                                              $[B,N_&#123;cls&#125;,H,W]$   2. 回归预测分支的输出维度为:                                      $[B,4*\text&#123;reg_max&#125;,H,W]$ 其中$B$为batch，$H，W$分别表示特征图高与宽</code></pre><p>我们知道对于anchor free的模型，对于特征图上的每一个点期望预测4个bbox的参数，yolox所预测为$[t_x, t_y, t_w, t_h]$<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click">[6]</span></a></sup>，yolov8参考FCOS<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://arxiv.org/abs/1904.01355">[7]</span></a></sup>预测的为$[l, t,r , b]$，具体如下图:</p><img src="/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/bbox.png" class=""><p>而和FCOS不同的是，yolov8并没有直接预测$[l, t,r , b]$的值，而是采用Generalized Focal Loss<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://zhuanlan.zhihu.com/p/147691786">[8]</span></a></sup>中的Distribution Focal Loss(DFL)通过预测一个离散分布计算得到:<br>                                                             $$\hat{y}&#x3D;\sum_{i&#x3D;0}^nP(y_i)y_i\tag{2}$$<br>由于是离散分布，所以有:$\sum_{i&#x3D;0}^nP(y_i)&#x3D;1$。<br>DFL的具体代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DFL</span>(nn.Module):  <br>    <span class="hljs-string">&quot;&quot;&quot;  </span><br><span class="hljs-string">    Integral module of Distribution Focal Loss (DFL).  </span><br><span class="hljs-string">    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391    &quot;&quot;&quot;</span>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, c1=<span class="hljs-number">16</span></span>):  <br>        <span class="hljs-string">&quot;&quot;&quot;Initialize a convolutional layer with a given number of input channels.&quot;&quot;&quot;</span>  <br>        <span class="hljs-built_in">super</span>().__init__()  <br>        self.conv = nn.Conv2d(c1, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>).requires_grad_(<span class="hljs-literal">False</span>)  <br>        x = torch.arange(c1, dtype=torch.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># [0,1.0,2.0,...,15.0]</span><br>        self.conv.weight.data[:] = nn.Parameter(x.view(<span class="hljs-number">1</span>, c1, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))  <br>        self.c1 = c1  <br>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):  <br>        <span class="hljs-string">&quot;&quot;&quot;Applies a transformer layer on input tensor &#x27;x&#x27; and returns a tensor.&quot;&quot;&quot;</span>  <br>        <span class="hljs-comment"># b:batch, c:channels=4*reg_max, a:anchors=HxW </span><br>        b, c, a = x.shape                                         <br>        <span class="hljs-keyword">return</span> self.conv(x.view(b, <span class="hljs-number">4</span>, self.c1, a).transpose(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>).softmax(<span class="hljs-number">1</span>)).view(b, <span class="hljs-number">4</span>, a)<br></code></pre></td></tr></table></figure><p>在代码DFL的<code>forward</code>中，由于输入x的维度为$[B,4<em>\text{reg_max},H</em>W]$， 输出的维度为$[B,4,H*W]$(其中4对应于$l, t,r , b$)，如果$\text{reg_max}$&#x3D;16, 则DFL的<code>forward</code>计算过程如下:<br><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406042346616.png" alt="image.png"></p><p>​                                                                               图7 不同预测参数的bbox表示</p><p>假设我们暂时不考虑上图计算过程的$B$和$H<em>W$维度, 计算过程大致为：如果$x$的shape为64，经过$x$.view、transpose与softmax将维度转换为shape均为$[1, 16]$的$x1、x2、x3、x4$,再分别与w对应相乘得到$l, t,r , b$，结合式(2)，$x1、x2、x3、x4$对应于$P(y_i)$，由于$\sum_{i&#x3D;0}^nP(y_i)&#x3D;1$，所以x1、x2、x3、x4中所有元素的和也均为1，比如$x1$&#x3D;0.1+0.3+0.1+0.2+0.3&#x3D;1，$y_i$对应于w，$\sum_{i&#x3D;0}^nP(y_i)y_i$分别对应于w</em>$x1^T$, w*$x2^T$,w*$x3^T$, w*$x4^T$。</p><p>由于softmax的取值范围为$[0, 1]$, 根据计算可以发现$l, t,r , b\in [0, \text{reg_max}-1]$, 如果$\text{reg_max}$&#x3D;16, 在特征图上所能预测的最大框$prebox_{max}$是$l, t,r , b$ 都取15时，此时框的高度和宽度$w_{max},h_{max}$&#x3D;30, 由于特征图相对于原始image的下采样倍数$stride\in [8, 16, 32]$，如果我们取最大下采样倍数$strid$&#x3D;32，则在原图上所能预测的最大box高度和宽度为$w_{max},h_{max}$&#x3D;$30*32$&#x3D;960，如果我们图像中的原始目标的宽度或高度过大，则会出现预测边界框小于原始目标的情况，比如如果我们有一个目标其实际的gt_box宽度为1000，但是我们实际能预测的最大宽度为960，这时就会导致预测不精准，此时则需要根据具体情况对$\text{reg_max}$作调整。<br><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062339664.png" alt="image.png"></p><p>​                                       图8 目标过大时的YOLOV8的实际GT框与预测框</p><h3 id="2-4-Loss"><a href="#2-4-Loss" class="headerlink" title="2.4 Loss"></a>2.4 Loss</h3><p>$$\mathrm{Loss}&#x3D;{\alpha\mathrm{L_{cls}}+\beta\mathrm{L_{ciou}}+\gamma \mathrm{L_{dfl}}}\tag{3}$$<br>YOLOv8损失主要分为两部分，<strong>分类损失</strong>:$L_{cls}$和<strong>边框回归损失</strong>:$L_{ciou}$和$L_{dfl}$, <strong>分类损失</strong>$L_{cls}$为交叉熵损失，<strong>边框回归损失</strong>的$L_{ciou}$为ciou loss，$\alpha$、$\beta$、$\gamma$ 表示各损失的平衡系数。$L_{cls}$即计算正样本损失也计算负样本损失，**$L_{ciou}$和$L_{dfl}$只计算正样本损失。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">bbox2dist</span>(<span class="hljs-params">anchor_points, bbox, reg_max</span>):  <br>    <span class="hljs-string">&quot;&quot;&quot;Transform bbox(xyxy) to dist(ltrb).&quot;&quot;&quot;</span>  <br>    x1y1, x2y2 = bbox.chunk(<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)  <br>    <span class="hljs-keyword">return</span> torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -<span class="hljs-number">1</span>).clamp_(<span class="hljs-number">0</span>, reg_max - <span class="hljs-number">0.01</span>)  <span class="hljs-comment"># dist (lt, rb)</span><br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_df_loss</span>(<span class="hljs-params">pred_dist, target</span>):  <br>    <span class="hljs-string">&quot;&quot;&quot;Return sum of left and right DFL losses.&quot;&quot;&quot;</span>  <br>    <span class="hljs-comment"># Distribution Focal Loss (DFL) proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391  </span><br>    tl = target.long()  <span class="hljs-comment"># target left  </span><br>    tr = tl + <span class="hljs-number">1</span>  <span class="hljs-comment"># target right  </span><br>    wl = tr - target  <span class="hljs-comment"># weight left  </span><br>    wr = <span class="hljs-number">1</span> - wl  <span class="hljs-comment"># weight right  </span><br>    <span class="hljs-keyword">return</span> (F.cross_entropy(pred_dist, tl.view(-<span class="hljs-number">1</span>), reduction=<span class="hljs-string">&#x27;none&#x27;</span>).view(tl.shape) * wl +  <br>            F.cross_entropy(pred_dist, tr.view(-<span class="hljs-number">1</span>), reduction=<span class="hljs-string">&#x27;none&#x27;</span>).view(tl.shape) * wr).mean(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>对于边框回归损失$L_{dfl}$，模型所预测的是$[l_{pre}, t_{pre},r_{pre} , b_{pre}]$，原始目标框的输入是$[x_{tar1},  y_{tar1}, x_{tar2}, y_{tar2}]$，通过使用bbox2dist函数将$[x_{tar1},  y_{tar1}, x_{tar2}, y_{tar2}]$转化为$[l_{tar}, t_{tar},r_{tar} , b_{tar}]$， 并将$[l_{pre}, t_{pre},r_{pre} , b_{pre}]$和$[l_{tar}, t_{tar},r_{tar} , b_{tar}]$作为计算dfl损失函数_df_loss的输入。代码_df_loss中$wl、wr$的计算如下图所示:<br><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405131751273.png" alt="image.png"></p><p>​                        图9 wr、wb与target_box的相对关系</p><p>由于代码<code>_df_loss</code>中<code>tl = target.long()</code>会直接对target_box的$l,t,r,b$向下取整，向下取整会使原值的波动范围为$[0, 1]$之间，1在图中正好是两个方格的宽度，$wl_l, wl_t, wl_r, wl_b$($wl &#x3D; tr - target$，$wl$由$wl_{l}、wl_{t}、wl_{r}、wl_{b}$组成)显示了偏外侧的程度，值越小则说明target_box的对应边在两个方格中越偏外侧box1(对应于代码<code>_df_loss</code>中的$tl$)，同理$wr_l, wr_t, wr_r, wr_b$($wr &#x3D; 1 - wl$，$wr$由$wr_{l}、wr_{t}、wr_{r}、wr_{b}$组成)则显示了偏内侧的程度，值越小则说明target_box的对应边越偏内侧box2(对应于代码<code>_df_loss</code>中的$tr$)。<br>我们再来看一下DFL的公式:<br>$$\mathbf{DFL}(\mathcal{S}<em>i,\mathcal{S}</em>{i+1})&#x3D;-\big((y_{i+1}-y)\log(\mathcal{S}<em>i)+(y-y_i)\log(\mathcal{S}</em>{i+1})\big)$$<br>其中:   $y_{i+1}-y$对应于代码<code>_df_loss</code>中的$wl$, $y-y_i$对应于$wr$<br>       $log(\mathcal{S}<em>i)$对应于:<br>      F.cross_entropy(pred_dist, tl.view(-1), reduction&#x3D;’none’)<br>      $log(\mathcal{S}</em>{i+1}$)对应于:<br>      &#96;F.cross_entropy(pred_dist, tr.view(-1), reduction&#x3D;’none’)</p><h3 id="2-5-正负样本匹配"><a href="#2-5-正负样本匹配" class="headerlink" title="2.5 正负样本匹配"></a>2.5 正负样本匹配</h3><p>正负样本匹配方面，YOLOV8和YOLOX均采用了动态的样本分配策略，YOLOV8采用了TOOD的 TaskAlignedAssigner方式，关于TOOD的详细讲解，可参考博文<sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><span class="hint--top hint--rounded" aria-label="[https://www.hbblog.cn/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/](https://www.hbblog.cn/论文解读/TOOD/)">[9]</span></a></sup>，YOLOX则采用了 simOTA方式，具体可参考视频<sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click&vd_source=81b307c731d291353c2f2db16d04d4f8">[10]</span></a></sup>。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://github.com/ultralytics/ultralytics">https://github.com/ultralytics/ultralytics</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://juejin.cn/post/7187726947252699192">https://juejin.cn/post/7187726947252699192</a><a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://github.com/ultralytics/yolov5/issues/8785">https://github.com/ultralytics/yolov5/issues/8785</a><a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a href="https://arxiv.org/abs/2107.08430">https://arxiv.org/abs/2107.08430</a><a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/599761847">https://zhuanlan.zhihu.com/p/599761847</a><a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a href="https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click">https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click</a><a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:7" class="footnote-text"><span><a href="https://arxiv.org/abs/1904.01355">https://arxiv.org/abs/1904.01355</a><a href="#fnref:7" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:8" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/147691786">https://zhuanlan.zhihu.com/p/147691786</a><a href="#fnref:8" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:9" class="footnote-text"><span><a href="https://www.hbblog.cn/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/">https://www.hbblog.cn/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/</a><a href="#fnref:9" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:10" class="footnote-text"><span><a href="https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click&vd_source=81b307c731d291353c2f2db16d04d4f8">https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click&amp;vd_source=81b307c731d291353c2f2db16d04d4f8</a><a href="#fnref:10" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Object Detection</tag>
      
      <tag>YOLO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker的常用命令</title>
    <link href="/2024/05/13/Docker%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <url>/2024/05/13/Docker%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[<h2 id="创建Docker"><a href="#创建Docker" class="headerlink" title="创建Docker"></a>创建Docker</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker run --gpus all -it --name 容器名 --shm-size 16G -v 原始目录:容器中的目录 镜像的REPOSITORY名:镜像的TAG  bash<br></code></pre></td></tr></table></figure><h2 id="查看已有的Docker镜像"><a href="#查看已有的Docker镜像" class="headerlink" title="查看已有的Docker镜像"></a>查看已有的Docker镜像</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker images<br></code></pre></td></tr></table></figure><h2 id="查看STATUS处于UP状态的Docker容器"><a href="#查看STATUS处于UP状态的Docker容器" class="headerlink" title="查看STATUS处于UP状态的Docker容器"></a>查看STATUS处于UP状态的Docker容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker ps                #只显示STATUS处于UP状态的，不显示STATUS处于EXITED状态的容器<br></code></pre></td></tr></table></figure><h2 id="查看全部的Docker容器"><a href="#查看全部的Docker容器" class="headerlink" title="查看全部的Docker容器"></a>查看全部的Docker容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker ps -a<br></code></pre></td></tr></table></figure><h2 id="服务器磁盘查看"><a href="#服务器磁盘查看" class="headerlink" title="服务器磁盘查看"></a>服务器磁盘查看</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">df   或用  df -mh<br></code></pre></td></tr></table></figure><h2 id="查看目录"><a href="#查看目录" class="headerlink" title="查看目录"></a>查看目录</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">l<br></code></pre></td></tr></table></figure><h2 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker start 容器名<br></code></pre></td></tr></table></figure><h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">docker attach 容器名<br>或 <br>docker exec -it 容器名 bash<br></code></pre></td></tr></table></figure><h2 id="退出容器"><a href="#退出容器" class="headerlink" title="退出容器"></a>退出容器</h2><h3 id="退出且停止"><a href="#退出且停止" class="headerlink" title="退出且停止"></a>退出且停止</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">exit   或  Ctrl+d<br></code></pre></td></tr></table></figure><h3 id="退出不停止"><a href="#退出不停止" class="headerlink" title="退出不停止"></a>退出不停止</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Ctrl+P+Q<br></code></pre></td></tr></table></figure><h2 id="修改容器名字"><a href="#修改容器名字" class="headerlink" title="修改容器名字"></a>修改容器名字</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker rename 原名 现名<br></code></pre></td></tr></table></figure><h2 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker rm 容器<br></code></pre></td></tr></table></figure><h2 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker rmi 镜像名<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试文章</title>
    <link href="/2024/04/22/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/"/>
    <url>/2024/04/22/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>这是一篇测试文章</p><p><img src="/images/test.png" alt="图片引用方法三"></p>]]></content>
    
    
    <categories>
      
      <category>test</category>
      
    </categories>
    
    
    <tags>
      
      <tag>test</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
