<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>YOLOv8详解</title>
    <link href="/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/"/>
    <url>/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<figure><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062225432.png" alt="image.png" /><figcaption>image.png</figcaption></figure><p>​ The YOLO Timeline</p><h3 id="yolov8-概述">1. YOLOV8 概述</h3><p>整体网络在YOLOV5的基础上进行了优化，并结合了YOLOV7的ELAN算法思想，基于缩放系数提供了n/s/m/l/x五种参数量依次增大的模型，并通过一套框架实现实例分割、姿势/关键点检测、目标检测和分类支持多种复杂任务<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://github.com/ultralytics/ultralytics">[1]</span></a></sup>。 <img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062231676.png" alt="图1 一套框架实现不同任务(源自https://github.com/ultralytics/ultralytics)" /></p><h3 id="yolov8检测算法整体模型结构">2. YOLOv8检测算法整体模型结构</h3><figure><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405151132320.png" alt="图2 整体结构图(源自https://github.com/open-mmlab/mmyolo/tree/dev/configs/yolov8)" /><figcaption>图2 整体结构图(源自https://github.com/open-mmlab/mmyolo/tree/dev/configs/yolov8)</figcaption></figure><p>从两个模型的yaml文件可以看出，不同尺度大小的模型，yolov5的最大通道采用了统一大小的最大通道，均为1024，yolov8中n/s、l/x分别采用了相同大小的最大通达，s/m/l则进行了精调, 主要目的是为了平衡各个模型的参数量。</p><img src="/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/20240122161239.png" class="" title="图3 YOLOv8与YOLOv5模型系数比较"><figure><img src="20240122161239.png" alt="图3 YOLOv8与YOLOv5模型系数比较" /><figcaption>图3 YOLOv8与YOLOv5模型系数比较</figcaption></figure><h3 id="backbone">2.1 Backbone</h3><img src="/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/20240122162925.png" class="" title="图4 YOLOv8与YOLOv5的Backbone比较"><p><strong>Backbone中yolov5和yolov8主要有两点差异:</strong> (1) 提取初步特征的第一个卷积层的卷积核kernel，yolov5为6x6, yolov8为3x3，感受野相比于yolov5进一步缩小<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://juejin.cn/post/7187726947252699192">[2]</span></a></sup>。</p><ol start="2" type="1"><li>yolov5中的C3模块在yolov8中被替换为了C2f，C2f则采用了yolov7中ELAN 多层堆叠的结构，增加了更多类似resnet残差块中的跳跃连接,丰富了模型的梯度流。 <img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405132056678.png" alt="image.png" /> 图5 C3与C2f对比图(源自https://openmmlab.medium.com/dive-into-yolov8-how-does-this-state-of-the-art-model-work-10f18f74bab1)</li></ol><h4 id="sppf模块">2.1.1 SPPF模块</h4><figure><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062235111.png" alt="image.png" /><figcaption>image.png</figcaption></figure><p>​ 图6 SPP与SPPF比较</p><p>SPP与SPPF有着相同的作用:实现多尺度特征融合。原始的SPP模块是由Joseph Redmon 在 YOLOv3 中实现的，采用不同大小池化kernel的并行结构，而SPPF首次使用是在YOLOv5中，采用了三个相同大小池化Kernel的并行+串行的结构, 增加了更多的跳跃连接。 为什么左侧SPP的Maxpooling，其kernel size分别是5，9，13, 而右侧SPPF的kernel size均是5呢？我们用感受野的公式计算一下感受野: <span class="math display">\[\begin{aligned}r_l&amp;=r_{l-1}+\left((k_l-1)*\prod_{i=1}^{l-1}s_i\right), l&gt;=2\end{aligned}\tag{1}\]</span> 其中: <span class="math inline">\(r_{l}\)</span>为第<span class="math inline">\(l\)</span>层的感受野， <span class="math inline">\(k_l\)</span>为第<span class="math inline">\(l\)</span>层的kernel size，<span class="math inline">\(s_i\)</span>为步长stride。 假设conv2d+BN+SiLU为第一层，令<span class="math inline">\(r_{1}\)</span>为1，则有:</p><table><thead><tr class="header"><th style="text-align: center;">右侧</th><th style="text-align: center;">左侧</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline">\(r_{k_1=5}\)</span>= 1+4*1=5</td><td style="text-align: center;"><span class="math inline">\(r_{k=5}\)</span> = 1+4*1=5</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(r_{k_2=5}\)</span>= 5+4*1=9</td><td style="text-align: center;"><span class="math inline">\(r_{k=9}\)</span> = 1+8*1=9</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline">\(r_{k_3=5}\)</span>= 9+4*1=13</td><td style="text-align: center;"><span class="math inline">\(r_{k=13}\)</span> = 1+12*1=13</td></tr></tbody></table><p>可以发现SPP和SPPF有着相同的感受野，但SPPF的浮点运算量更少，所以速度更快<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://github.com/ultralytics/yolov5/issues/8785">[3]</span></a></sup>。</p><h3 id="neck">2.2 Neck</h3><p>Neck部分采用FPN和PAN结合的结构，实现浅层特征与深层特征的相互融合，共提取三个有效特征层给Head: feat1=(80, 80, 256<em><span class="math inline">\(w\)</span>)、feat2=(40, 40, 512</em><span class="math inline">\(w\)</span>)、feat3=(20, 20, 512<span class="math inline">\(*w*r\)</span>){其中<span class="math inline">\(w,r\)</span>为模型系数}, 并将三个特征层作为Head的输入。</p><h3 id="head">2.3 Head</h3><table><thead><tr class="header"><th><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405131645079.png" /></th></tr></thead><tbody><tr class="odd"><td><img src="/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/YOLOX_Head.png" class="" title="YOLOX Head"></td></tr><tr class="even"><td><img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405141639782.png" alt="image.png" /><br><br></td></tr></tbody></table><p>yolov5、yolox和yolov8三者的Head中，yolov5为ancher base，yolov8和yolox为ancher free, 并且yolov8和yolox均用了decoupled detection head(两个并行分支分别完成检测和分类，yolox的论文显示采用decoupled detection head能够提升AP约1.1个百分点<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://arxiv.org/abs/2107.08430">[4]</span></a></sup>),预测输出方面:</p><p>yolov5: 对于特征图上的每一个grid cell预测(<span class="math inline">\(N_{cls}\)</span> + 4 + 1)x3个参数，其中<span class="math inline">\(N_{cls}\)</span>表示类别数，<code>4</code>表示网络预测bbox的相关参数，<code>1</code>表示是否有目标。</p><p>yolox: 对于特征图上的每个grid point预测(<span class="math inline">\(N_{cls}\)</span> + 4 + 1)个参数。<span class="math inline">\(N_{cls}\)</span>、<code>4</code>、<code>1</code>的含义和yolov5相同。对于有80个类别的coco数据集， 三个检查头所预测的参数个数分别为80x80x(80 + 4 + 1)、40x40x(80 + 4 + 1)、20x20x(80 + 4 + 1)个参数。</p><p>yolov8: yolov8消除了yolox中判断是否有物体的obj. 分支， 对于特征图上的每个特征点预测(<span class="math inline">\(N_{cls}\)</span> + 4* <span class="math inline">\(\text{reg_max}\)</span>)个参数，在yolox中分类和回归分支的通道数均为256，yolov8认为作为两个不同的分支，用于表征不同的特征，通道数不应该是相等的<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://zhuanlan.zhihu.com/p/599761847">[5]</span></a></sup>，对于分类分支通倒数<span class="math inline">\(C_{cls}\)</span> 设置为<span class="math inline">\(max(C^{3},min(N_{cls},100))\)</span>，回归分支的通道数<span class="math inline">\(C_{reg}\)</span>为<span class="math inline">\(max(16,C^{3}/4,4*\text{reg_max})\)</span>。对于有80个类别的coco数据集，假设设<span class="math inline">\(\text{reg_max}\)</span> 为16，<span class="math inline">\(w\)</span> 取1: <span class="math display">\[ \begin{aligned}&amp;C_{cls}=max(256,min(80, 100))=256 \\&amp;C_{reg}=max(16,256/4,4*16)=64\end{aligned} \]</span> 对于YOLOv8两个分支最后的Conv2d模块:</p><ol type="1"><li><p>类别预测分支输出的维度为:</p><pre><code class="hljs">                        $[B,N_&#123;cls&#125;,H,W]$  </code></pre></li><li><p>回归预测分支的输出维度为:<br /><span class="math inline">\([B,4*\text{reg_max},H,W]\)</span></p><p>其中<span class="math inline">\(B\)</span>为batch，<span class="math inline">\(H，W\)</span>分别表示特征图高与宽</p></li></ol><p>我们知道对于anchor free的模型，对于特征图上的每一个点期望预测4个bbox的参数，yolox所预测为<span class="math inline">\([t_x, t_y, t_w, t_h]\)</span><sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click">[6]</span></a></sup>，yolov8参考FCOS<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://arxiv.org/abs/1904.01355">[7]</span></a></sup>预测的为<span class="math inline">\([l, t,r , b]\)</span>，具体如下图: <img src="/2024/06/10/YOLOv8%E8%AF%A6%E8%A7%A3/bbox.png" class=""> 而和FCOS不同的是，yolov8并没有直接预测<span class="math inline">\([l, t,r , b]\)</span>的值，而是采用Generalized Focal Loss<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://zhuanlan.zhihu.com/p/147691786">[8]</span></a></sup>中的Distribution Focal Loss(DFL)通过预测一个离散分布计算得到: <span class="math display">\[\hat{y}=\sum_{i=0}^nP(y_i)y_i\tag{2}\]</span> 由于是离散分布，所以有:<span class="math inline">\(\sum_{i=0}^nP(y_i)=1\)</span>。 DFL的具体代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DFL</span>(nn.Module):  <br>    <span class="hljs-string">&quot;&quot;&quot;  </span><br><span class="hljs-string">    Integral module of Distribution Focal Loss (DFL).  </span><br><span class="hljs-string">    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391    &quot;&quot;&quot;</span>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, c1=<span class="hljs-number">16</span></span>):  <br>        <span class="hljs-string">&quot;&quot;&quot;Initialize a convolutional layer with a given number of input channels.&quot;&quot;&quot;</span>  <br>        <span class="hljs-built_in">super</span>().__init__()  <br>        self.conv = nn.Conv2d(c1, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>).requires_grad_(<span class="hljs-literal">False</span>)  <br>        x = torch.arange(c1, dtype=torch.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># [0,1.0,2.0,...,15.0]</span><br>        self.conv.weight.data[:] = nn.Parameter(x.view(<span class="hljs-number">1</span>, c1, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))  <br>        self.c1 = c1  <br>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):  <br>        <span class="hljs-string">&quot;&quot;&quot;Applies a transformer layer on input tensor &#x27;x&#x27; and returns a tensor.&quot;&quot;&quot;</span>  <br>        <span class="hljs-comment"># b:batch, c:channels=4*reg_max, a:anchors=HxW </span><br>        b, c, a = x.shape                                         <br>        <span class="hljs-keyword">return</span> self.conv(x.view(b, <span class="hljs-number">4</span>, self.c1, a).transpose(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>).softmax(<span class="hljs-number">1</span>)).view(b, <span class="hljs-number">4</span>, a)<br></code></pre></td></tr></table></figure><p>在代码DFL的<code>forward</code>中，由于输入x的维度为<span class="math inline">\([B,4*\text{reg_max},H*W]\)</span>， 输出的维度为<span class="math inline">\([B,4,H*W]\)</span>(其中4对应于<span class="math inline">\(l, t,r , b\)</span>)，如果<span class="math inline">\(\text{reg_max}\)</span>=16, 则DFL的<code>forward</code>计算过程如下: <img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406042346616.png" alt="image.png" /></p><p>​ 图7 不同预测参数的bbox表示</p><p>假设我们暂时不考虑上图计算过程的<span class="math inline">\(B\)</span>和<span class="math inline">\(H*W\)</span>维度, 计算过程大致为：如果<span class="math inline">\(x\)</span>的shape为64，经过<span class="math inline">\(x\)</span>.view、transpose与softmax将维度转换为shape均为<span class="math inline">\([1, 16]\)</span>的<span class="math inline">\(x1、x2、x3、x4\)</span>,再分别与w对应相乘得到<span class="math inline">\(l, t,r , b\)</span>，结合式(2)，<span class="math inline">\(x1、x2、x3、x4\)</span>对应于<span class="math inline">\(P(y_i)\)</span>，由于<span class="math inline">\(\sum_{i=0}^nP(y_i)=1\)</span>，所以x1、x2、x3、x4中所有元素的和也均为1，比如<span class="math inline">\(x1\)</span>=0.1+0.3+0.1+0.2+0.3=1，<span class="math inline">\(y_i\)</span>对应于w，<span class="math inline">\(\sum_{i=0}^nP(y_i)y_i\)</span>分别对应于w<em><span class="math inline">\(x1^T\)</span>, w</em><span class="math inline">\(x2^T\)</span>,w<em><span class="math inline">\(x3^T\)</span>, w</em><span class="math inline">\(x4^T\)</span>。</p><p>由于softmax的取值范围为<span class="math inline">\([0, 1]\)</span>, 根据计算可以发现<span class="math inline">\(l, t,r , b\in [0, \text{reg_max}-1]\)</span>, 如果<span class="math inline">\(\text{reg_max}\)</span>=16, 在特征图上所能预测的最大框<span class="math inline">\(prebox_{max}\)</span>是<span class="math inline">\(l, t,r , b\)</span> 都取15时，此时框的高度和宽度<span class="math inline">\(w_{max},h_{max}\)</span>=30, 由于特征图相对于原始image的下采样倍数<span class="math inline">\(stride\in [8, 16, 32]\)</span>，如果我们取最大下采样倍数<span class="math inline">\(strid\)</span>=32，则在原图上所能预测的最大box高度和宽度为<span class="math inline">\(w_{max},h_{max}\)</span>=<span class="math inline">\(30*32\)</span>=960，如果我们图像中的原始目标的宽度或高度过大，则会出现预测边界框小于原始目标的情况，比如如果我们有一个目标其实际的gt_box宽度为1000，但是我们实际能预测的最大宽度为960，这时就会导致预测不精准，此时则需要根据具体情况对<span class="math inline">\(\text{reg_max}\)</span>作调整。 <img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202406062339664.png" alt="image.png" /></p><p>​ 图8 目标过大时的YOLOV8的实际GT框与预测框</p><h3 id="loss">2.4 Loss</h3><p><span class="math display">\[\mathrm{Loss}={\alpha\mathrm{L_{cls}}+\beta\mathrm{L_{ciou}}+\gamma \mathrm{L_{dfl}}}\tag{3}\]</span> YOLOv8损失主要分为两部分，<strong>分类损失</strong>:<span class="math inline">\(L_{cls}\)</span>和<strong>边框回归损失</strong>:<span class="math inline">\(L_{ciou}\)</span>和<span class="math inline">\(L_{dfl}\)</span>, <strong>分类损失</strong><span class="math inline">\(L_{cls}\)</span>为交叉熵损失，<strong>边框回归损失</strong>的<span class="math inline">\(L_{ciou}\)</span>为ciou loss，<span class="math inline">\(\alpha\)</span>、<span class="math inline">\(\beta\)</span>、<span class="math inline">\(\gamma\)</span> 表示各损失的平衡系数。<span class="math inline">\(L_{cls}\)</span>即计算正样本损失也计算负样本损失，**<span class="math inline">\(L_{ciou}\)</span>和<span class="math inline">\(L_{dfl}\)</span>只计算正样本损失。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">bbox2dist</span>(<span class="hljs-params">anchor_points, bbox, reg_max</span>):  <br>    <span class="hljs-string">&quot;&quot;&quot;Transform bbox(xyxy) to dist(ltrb).&quot;&quot;&quot;</span>  <br>    x1y1, x2y2 = bbox.chunk(<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)  <br>    <span class="hljs-keyword">return</span> torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -<span class="hljs-number">1</span>).clamp_(<span class="hljs-number">0</span>, reg_max - <span class="hljs-number">0.01</span>)  <span class="hljs-comment"># dist (lt, rb)</span><br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_df_loss</span>(<span class="hljs-params">pred_dist, target</span>):  <br>    <span class="hljs-string">&quot;&quot;&quot;Return sum of left and right DFL losses.&quot;&quot;&quot;</span>  <br>    <span class="hljs-comment"># Distribution Focal Loss (DFL) proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391  </span><br>    tl = target.long()  <span class="hljs-comment"># target left  </span><br>    tr = tl + <span class="hljs-number">1</span>  <span class="hljs-comment"># target right  </span><br>    wl = tr - target  <span class="hljs-comment"># weight left  </span><br>    wr = <span class="hljs-number">1</span> - wl  <span class="hljs-comment"># weight right  </span><br>    <span class="hljs-keyword">return</span> (F.cross_entropy(pred_dist, tl.view(-<span class="hljs-number">1</span>), reduction=<span class="hljs-string">&#x27;none&#x27;</span>).view(tl.shape) * wl +  <br>            F.cross_entropy(pred_dist, tr.view(-<span class="hljs-number">1</span>), reduction=<span class="hljs-string">&#x27;none&#x27;</span>).view(tl.shape) * wr).mean(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>对于边框回归损失<span class="math inline">\(L_{dfl}\)</span>，模型所预测的是<span class="math inline">\([l_{pre}, t_{pre},r_{pre} , b_{pre}]\)</span>，原始目标框的输入是<span class="math inline">\([x_{tar1}, y_{tar1}, x_{tar2}, y_{tar2}]\)</span>，通过使用bbox2dist函数将<span class="math inline">\([x_{tar1}, y_{tar1}, x_{tar2}, y_{tar2}]\)</span>转化为<span class="math inline">\([l_{tar}, t_{tar},r_{tar} , b_{tar}]\)</span>， 并将<span class="math inline">\([l_{pre}, t_{pre},r_{pre} , b_{pre}]\)</span>和<span class="math inline">\([l_{tar}, t_{tar},r_{tar} , b_{tar}]\)</span>作为计算dfl损失函数_df_loss的输入。代码_df_loss中<span class="math inline">\(wl、wr\)</span>的计算如下图所示: <img src="https://makedown-imgs.oss-cn-hangzhou.aliyuncs.com/imgs/202405131751273.png" alt="image.png" /></p><p>​ 图9 wr、wb与target_box的相对关系</p><p>由于代码<code>_df_loss</code>中<code>tl = target.long()</code>会直接对target_box的<span class="math inline">\(l,t,r,b\)</span>向下取整，向下取整会使原值的波动范围为<span class="math inline">\([0, 1]\)</span>之间，1在图中正好是两个方格的宽度，<span class="math inline">\(wl_l, wl_t, wl_r, wl_b\)</span>(<span class="math inline">\(wl = tr - target\)</span>，<span class="math inline">\(wl\)</span>由<span class="math inline">\(wl_{l}、wl_{t}、wl_{r}、wl_{b}\)</span>组成)显示了偏外侧的程度，值越小则说明target_box的对应边在两个方格中越偏外侧box1(对应于代码<code>_df_loss</code>中的<span class="math inline">\(tl\)</span>)，同理<span class="math inline">\(wr_l, wr_t, wr_r, wr_b\)</span>(<span class="math inline">\(wr = 1 - wl\)</span>，<span class="math inline">\(wr\)</span>由<span class="math inline">\(wr_{l}、wr_{t}、wr_{r}、wr_{b}\)</span>组成)则显示了偏内侧的程度，值越小则说明target_box的对应边越偏内侧box2(对应于代码<code>_df_loss</code>中的<span class="math inline">\(tr\)</span>)。 我们再来看一下DFL的公式: <span class="math display">\[\mathbf{DFL}(\mathcal{S}_i,\mathcal{S}_{i+1})=-\big((y_{i+1}-y)\log(\mathcal{S}_i)+(y-y_i)\log(\mathcal{S}_{i+1})\big)\]</span> 其中: <span class="math inline">\(y_{i+1}-y\)</span>对应于代码<code>_df_loss</code>中的<span class="math inline">\(wl\)</span>, <span class="math inline">\(y-y_i\)</span>对应于<span class="math inline">\(wr\)</span> <span class="math inline">\(log(\mathcal{S}_i)\)</span>对应于: F.cross_entropy(pred_dist, tl.view(-1), reduction='none') <span class="math inline">\(log(\mathcal{S}_{i+1}\)</span>)对应于: `F.cross_entropy(pred_dist, tr.view(-1), reduction='none')</p><h3 id="正负样本匹配">2.5 正负样本匹配</h3><p>正负样本匹配方面，YOLOV8和YOLOX均采用了动态的样本分配策略，YOLOV8采用了TOOD的 TaskAlignedAssigner方式，关于TOOD的详细讲解，可参考博文<sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="[https://www.hbblog.cn/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/](https://www.hbblog.cn/论文解读/TOOD/)">[9]</span></a></sup>，YOLOX则采用了 simOTA方式，具体可参考视频<sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><span class="hint--top hint--rounded" data-aria-label="https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click&amp;vd_source=81b307c731d291353c2f2db16d04d4f8">[10]</span></a></sup>。</p><h3 id="reference">Reference</h3><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>https://github.com/ultralytics/ultralytics <a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>https://juejin.cn/post/7187726947252699192 <a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>https://github.com/ultralytics/yolov5/issues/8785 <a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>https://arxiv.org/abs/2107.08430 <a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span>https://zhuanlan.zhihu.com/p/599761847 <a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span>https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click <a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:7" class="footnote-text"><span>https://arxiv.org/abs/1904.01355 <a href="#fnref:7" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:8" class="footnote-text"><span>https://zhuanlan.zhihu.com/p/147691786 <a href="#fnref:8" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:9" class="footnote-text"><span><a href="https://www.hbblog.cn/论文解读/TOOD/">https://www.hbblog.cn/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/TOOD/</a> <a href="#fnref:9" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:10" class="footnote-text"><span>https://www.bilibili.com/video/BV1JW4y1k76c/?spm_id_from=333.337.search-card.all.click&amp;vd_source=81b307c731d291353c2f2db16d04d4f8 <a href="#fnref:10" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Object Detection</tag>
      
      <tag>YOLO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker的常用命令</title>
    <link href="/2024/05/13/Docker%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <url>/2024/05/13/Docker%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[<h2 id="创建docker">创建Docker</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker run --gpus all -it --name 容器名 --shm-size 16G -v 原始目录:容器中的目录 镜像的REPOSITORY名:镜像的TAG  bash<br></code></pre></td></tr></table></figure><h2 id="查看已有的docker镜像">查看已有的Docker镜像</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker images<br></code></pre></td></tr></table></figure><h2 id="查看status处于up状态的docker容器">查看STATUS处于UP状态的Docker容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker ps                #只显示STATUS处于UP状态的，不显示STATUS处于EXITED状态的容器<br></code></pre></td></tr></table></figure><h2 id="查看全部的docker容器">查看全部的Docker容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker ps -a<br></code></pre></td></tr></table></figure><h2 id="服务器磁盘查看">服务器磁盘查看</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">df   或用  df -mh<br></code></pre></td></tr></table></figure><h2 id="查看目录">查看目录</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">l<br></code></pre></td></tr></table></figure><h2 id="启动容器">启动容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker start 容器名<br></code></pre></td></tr></table></figure><h2 id="进入容器">进入容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">docker attach 容器名<br>或 <br>docker exec -it 容器名 bash<br></code></pre></td></tr></table></figure><h2 id="退出容器">退出容器</h2><h3 id="退出且停止">退出且停止</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">exit   或  Ctrl+d<br></code></pre></td></tr></table></figure><h3 id="退出不停止">退出不停止</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Ctrl+P+Q<br></code></pre></td></tr></table></figure><h2 id="修改容器名字">修改容器名字</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker rename 原名 现名<br></code></pre></td></tr></table></figure><h2 id="删除容器">删除容器</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker rm 容器<br></code></pre></td></tr></table></figure><h2 id="删除镜像">删除镜像</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">docker rmi 镜像名<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试文章</title>
    <link href="/2024/04/22/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/"/>
    <url>/2024/04/22/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>这是一篇测试文章</p><figure><img src="/images/test.png" alt="图片引用方法三" /><figcaption>图片引用方法三</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>test</category>
      
    </categories>
    
    
    <tags>
      
      <tag>test</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
